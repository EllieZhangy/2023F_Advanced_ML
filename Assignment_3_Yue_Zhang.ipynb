{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOyo2s6a5VGEAYt+4Hj5l9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9e09dbe08a145e3b87dbd2f672d80a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2900f30843cf43d9b73c643a846d5545",
              "IPY_MODEL_24e85d0314354ac9aeb6452200fc2414",
              "IPY_MODEL_47ffd85be6274d2a83dff1417227bc4e"
            ],
            "layout": "IPY_MODEL_f9ec3008744d4ee9939dc604620a305f"
          }
        },
        "2900f30843cf43d9b73c643a846d5545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64263557b32459b92d7b6271e874f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_8667ed82a45f488a97c9a6d6e8f2b06e",
            "value": "Map: 100%"
          }
        },
        "24e85d0314354ac9aeb6452200fc2414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10e026db1ce40da81ac4dcae1da5269",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94300165b2c646058f420d4aa1caba11",
            "value": 10000
          }
        },
        "47ffd85be6274d2a83dff1417227bc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21392a4c49647819fc199e39c867da0",
            "placeholder": "​",
            "style": "IPY_MODEL_b32268e9d90a4982b81fff8642f4d7e1",
            "value": " 10000/10000 [00:01&lt;00:00, 6267.19 examples/s]"
          }
        },
        "f9ec3008744d4ee9939dc604620a305f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64263557b32459b92d7b6271e874f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8667ed82a45f488a97c9a6d6e8f2b06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10e026db1ce40da81ac4dcae1da5269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94300165b2c646058f420d4aa1caba11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f21392a4c49647819fc199e39c867da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32268e9d90a4982b81fff8642f4d7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b63e6155f64f35b382777b2878a31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f2b721f4f0e48e2a770fc6e9985339b",
              "IPY_MODEL_b7a98b4119f74597a03d93b30785ff9a",
              "IPY_MODEL_a09cd7206ff44b9195107a66729f413c"
            ],
            "layout": "IPY_MODEL_bfd1517a21bb4a128ea9166dc02b523b"
          }
        },
        "2f2b721f4f0e48e2a770fc6e9985339b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7875b345f407482393797730fa3ba428",
            "placeholder": "​",
            "style": "IPY_MODEL_eede4bc327e245238e7d636a203d9dad",
            "value": "Map: 100%"
          }
        },
        "b7a98b4119f74597a03d93b30785ff9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051dc72ff7544f6491d4414d10d9d309",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fbcf47d41f94884bf6a064ba0878f4d",
            "value": 10000
          }
        },
        "a09cd7206ff44b9195107a66729f413c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007ad67bc4fa4ae2a25f6416dc2ac0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_a7800d3fc189443b9aa5e5c266121858",
            "value": " 10000/10000 [00:01&lt;00:00, 6897.97 examples/s]"
          }
        },
        "bfd1517a21bb4a128ea9166dc02b523b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7875b345f407482393797730fa3ba428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eede4bc327e245238e7d636a203d9dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051dc72ff7544f6491d4414d10d9d309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbcf47d41f94884bf6a064ba0878f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "007ad67bc4fa4ae2a25f6416dc2ac0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7800d3fc189443b9aa5e5c266121858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EllieZhangy/2023F_Advanced_ML/blob/main/Assignment_3_Yue_Zhang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3, Yue Zhang, Oct.20th"
      ],
      "metadata": {
        "id": "pGkYqPuhewp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "• Use papluca/language-identification dataset from Hugging Face to train a text classifier to identify the language of a text."
      ],
      "metadata": {
        "id": "IIRmdtqxeyfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4mYvk9afEQ8",
        "outputId": "58485bb3-9183-4934-bc63-abd3d614c07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: safetensors, dill, multiprocess, huggingface-hub, tokenizers, transformers, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "-fawfIwKkIwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Load Dataset"
      ],
      "metadata": {
        "id": "hAxR-XYzgZMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"papluca/language-identification\")"
      ],
      "metadata": {
        "id": "gA96UQvyfEYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n",
        "print(dataset['train'][0])  # Print the first instance from the training set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgye5NGEgpjK",
        "outputId": "93cedbd1-62b5-45b2-d69f-80e4c11f28f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['labels', 'text'],\n",
            "        num_rows: 70000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['labels', 'text'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['labels', 'text'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n",
            "{'labels': 'pt', 'text': 'os chefes de defesa da estónia, letónia, lituânia, alemanha, itália, espanha e eslováquia assinarão o acordo para fornecer pessoal e financiamento para o centro.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptFBVCm_0QMo",
        "outputId": "293fc4c8-90e0-43b3-9987-42dbcf309380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'labels': ['pt', 'bg', 'zh', 'th', 'ru', 'pl', 'ur', 'sw', 'tr', 'ur'], 'text': ['os chefes de defesa da estónia, letónia, lituânia, alemanha, itália, espanha e eslováquia assinarão o acordo para fornecer pessoal e financiamento para o centro.', 'размерът на хоризонталната мрежа може да бъде по реда на няколко километра ( km ) за на симулация до около 100 km за на симулация .', '很好，以前从不去评价，不知道浪费了多少积分，现在知道积分可以换钱，就要好好评价了，后来我就把这段话复制走了，既能赚积分，还省事，走到哪复制到哪，最重要的是，不用认真的评论了，不用想还差多少字，直接发出就可以了，推荐给大家！！', 'สำหรับ ของเก่า ที่ จริงจัง ลอง   honeychurch   ของเก่า ที่ ไม่   29   สำหรับ เฟอร์นิเจอร์ และ เงิน ไท ร้อง บริษัท ที่   122   สำหรับ ลาย คราม', 'Он увеличил давление .', 'S Jak sobie życzysz: Widzisz, jak Hitler zabija Żydów?', 'اس کے بارے میں ، سفید شادی کی شرح کے بعد سفید اورنمایاں طور پر سفید اورنمایاں طور پر .', 'Zabuni ya ushindani pia imekuwa rahisi kwa sifa ya kurudi kwenye mapendekezo yake ya grant , na dudovitz hivi karibuni ilikuwa kulea kwa ajili ya kuendeleza nyenzo za matangazo ya slick na kushiriki fedha kwa mipango nyingine ya mapendeleo ya umma kwa juhudi za shirikishi za afya , utetezi wa sera , homelessness , nyumbani msaada wa vurugu , msaada wa kibinafsi na maendeleo ya teknolojia .', \"Devasa 12 yüzyıl abbatiale saint-Pierre-Et-Saint-Paul , Aziz Peter ' ın 17 yüzyılda Roma ' da tamamlama kadar Hıristiyan ' en büyük kilisesi idi .\", 'موجودہ اثاثوں میں سے ایک کا اضافہ ہو سکتا ہے ۔']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Data Preprocessing"
      ],
      "metadata": {
        "id": "Vl-ELNyFgtKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Mapping for Language Codes:"
      ],
      "metadata": {
        "id": "mHhP-ROsj5Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_langs = sorted(list(set(dataset['train']['labels'])))\n",
        "lang2id = {lang: id for id, lang in enumerate(unique_langs)}\n",
        "id2lang = {id: lang for lang, id in lang2id.items()}\n",
        "\n",
        "num_labels = len(unique_langs)  # Determine the number of unique labels here"
      ],
      "metadata": {
        "id": "9QFd6YR0j5vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(id2lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCsjaf6cz-TC",
        "outputId": "2654e47c-a1b9-4b4f-ca5b-d2b9e35413b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'ar', 1: 'bg', 2: 'de', 3: 'el', 4: 'en', 5: 'es', 6: 'fr', 7: 'hi', 8: 'it', 9: 'ja', 10: 'nl', 11: 'pl', 12: 'pt', 13: 'ru', 14: 'sw', 15: 'th', 16: 'tr', 17: 'ur', 18: 'vi', 19: 'zh'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize:"
      ],
      "metadata": {
        "id": "dD_84DRcC1SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def encode_batch(batch):\n",
        "    batch['labels'] = [lang2id[label] for label in batch['labels']]\n",
        "    encoding = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
        "    return {**encoding, 'labels': batch['labels']}\n",
        "\n",
        "dataset = dataset.map(encode_batch, batched=True)"
      ],
      "metadata": {
        "id": "mXt6d98Cj8iR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a8b63e6155f64f35b382777b2878a31f",
            "2f2b721f4f0e48e2a770fc6e9985339b",
            "b7a98b4119f74597a03d93b30785ff9a",
            "a09cd7206ff44b9195107a66729f413c",
            "bfd1517a21bb4a128ea9166dc02b523b",
            "7875b345f407482393797730fa3ba428",
            "eede4bc327e245238e7d636a203d9dad",
            "051dc72ff7544f6491d4414d10d9d309",
            "8fbcf47d41f94884bf6a064ba0878f4d",
            "007ad67bc4fa4ae2a25f6416dc2ac0a1",
            "a7800d3fc189443b9aa5e5c266121858"
          ]
        },
        "outputId": "096dbf57-0fd7-4bcc-8def-8f1407e371fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8b63e6155f64f35b382777b2878a31f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Model Traning"
      ],
      "metadata": {
        "id": "z0BQA-G6C5wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCUUu0YhkiK5",
        "outputId": "caa52278-e317-46b5-cc8e-a1f1d787e9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "   output_dir='./results',\n",
        "   num_train_epochs=3,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   logging_dir='./logs',\n",
        "   logging_steps=200,\n",
        "   do_train=True,\n",
        "   do_eval=True,\n",
        "   evaluation_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=dataset['train'],\n",
        "   eval_dataset=dataset['validation'],\n",
        "   compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).astype(float).mean().item()}\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mWI93ZEBkiNX",
        "outputId": "b0fd4f46-2542-43fb-ec38-22d7ba923eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9560' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 9560/13125 31:03 < 11:35, 5.13 it/s, Epoch 2.18/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>0.063967</td>\n",
              "      <td>0.989400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.065300</td>\n",
              "      <td>0.063482</td>\n",
              "      <td>0.986400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.068500</td>\n",
              "      <td>0.079757</td>\n",
              "      <td>0.983800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.052009</td>\n",
              "      <td>0.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>0.036615</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.049000</td>\n",
              "      <td>0.049350</td>\n",
              "      <td>0.988700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.038935</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.054800</td>\n",
              "      <td>0.064092</td>\n",
              "      <td>0.987300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>0.068617</td>\n",
              "      <td>0.990900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.046900</td>\n",
              "      <td>0.060376</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.055464</td>\n",
              "      <td>0.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.050157</td>\n",
              "      <td>0.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.053095</td>\n",
              "      <td>0.991400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>0.066537</td>\n",
              "      <td>0.990600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.042200</td>\n",
              "      <td>0.060338</td>\n",
              "      <td>0.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.071326</td>\n",
              "      <td>0.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.049862</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.063326</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.051620</td>\n",
              "      <td>0.991900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.033700</td>\n",
              "      <td>0.070055</td>\n",
              "      <td>0.990300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.062180</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>0.063447</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.047276</td>\n",
              "      <td>0.992500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.068031</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.092400</td>\n",
              "      <td>0.989600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.056193</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.062547</td>\n",
              "      <td>0.989900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>0.052470</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.050474</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.018500</td>\n",
              "      <td>0.047834</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.048321</td>\n",
              "      <td>0.989700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.020600</td>\n",
              "      <td>0.043035</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>0.063912</td>\n",
              "      <td>0.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.021100</td>\n",
              "      <td>0.049803</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.054654</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.064518</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.065403</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.055681</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.063418</td>\n",
              "      <td>0.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.010100</td>\n",
              "      <td>0.054102</td>\n",
              "      <td>0.994400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>0.058294</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.055977</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.008800</td>\n",
              "      <td>0.059386</td>\n",
              "      <td>0.993900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.063485</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.065567</td>\n",
              "      <td>0.993200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.065525</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.058159</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13125' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13125/13125 42:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>0.063967</td>\n",
              "      <td>0.989400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.065300</td>\n",
              "      <td>0.063482</td>\n",
              "      <td>0.986400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.068500</td>\n",
              "      <td>0.079757</td>\n",
              "      <td>0.983800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.052009</td>\n",
              "      <td>0.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>0.036615</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.049000</td>\n",
              "      <td>0.049350</td>\n",
              "      <td>0.988700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.038935</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.054800</td>\n",
              "      <td>0.064092</td>\n",
              "      <td>0.987300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>0.068617</td>\n",
              "      <td>0.990900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.046900</td>\n",
              "      <td>0.060376</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.055464</td>\n",
              "      <td>0.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.050157</td>\n",
              "      <td>0.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.053095</td>\n",
              "      <td>0.991400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>0.066537</td>\n",
              "      <td>0.990600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.042200</td>\n",
              "      <td>0.060338</td>\n",
              "      <td>0.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.071326</td>\n",
              "      <td>0.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.049862</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.063326</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.051620</td>\n",
              "      <td>0.991900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.033700</td>\n",
              "      <td>0.070055</td>\n",
              "      <td>0.990300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.062180</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>0.063447</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.047276</td>\n",
              "      <td>0.992500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.068031</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.092400</td>\n",
              "      <td>0.989600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.056193</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.062547</td>\n",
              "      <td>0.989900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>0.052470</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.050474</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.018500</td>\n",
              "      <td>0.047834</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.048321</td>\n",
              "      <td>0.989700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.020600</td>\n",
              "      <td>0.043035</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>0.063912</td>\n",
              "      <td>0.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.021100</td>\n",
              "      <td>0.049803</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.054654</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.064518</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.065403</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.055681</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.063418</td>\n",
              "      <td>0.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.010100</td>\n",
              "      <td>0.054102</td>\n",
              "      <td>0.994400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>0.058294</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.055977</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.008800</td>\n",
              "      <td>0.059386</td>\n",
              "      <td>0.993900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.063485</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.065567</td>\n",
              "      <td>0.993200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.065525</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.058159</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.057356</td>\n",
              "      <td>0.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.007900</td>\n",
              "      <td>0.056938</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>0.050880</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.054109</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.056237</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.063450</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>0.064868</td>\n",
              "      <td>0.994100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.063792</td>\n",
              "      <td>0.994500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.059648</td>\n",
              "      <td>0.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.010800</td>\n",
              "      <td>0.062974</td>\n",
              "      <td>0.993800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.063272</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.064842</td>\n",
              "      <td>0.993700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.059110</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.060972</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.059875</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.059753</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.061376</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>0.061460</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13125, training_loss=0.0315351917834509, metrics={'train_runtime': 2570.076, 'train_samples_per_second': 81.71, 'train_steps_per_second': 5.107, 'total_flos': 1.39135417344e+16, 'train_loss': 0.0315351917834509, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Model Evaluation"
      ],
      "metadata": {
        "id": "2cSVyyjuDDV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model's performance on the test set:"
      ],
      "metadata": {
        "id": "0lsUbvKkDLy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(dataset['test'])\n",
        "print(\"Test Accuracy with Average Embeddings:\", results[\"eval_accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "10UKnj5FetQh",
        "outputId": "25d05f81-d36c-4510-bee5-d0291249bc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with Average Embeddings: 0.9931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usage:"
      ],
      "metadata": {
        "id": "G11I_QoZDFfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Prediction function\n",
        "def predict_language(text):\n",
        "    inputs = tokenizer(text, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Ensure inputs are on the correct device\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    pred_id = logits.argmax(-1).item()\n",
        "    return id2lang[pred_id]\n",
        "\n",
        "# Test the prediction function\n",
        "test_text = \"os chefes de defesa da estónia\"\n",
        "print(predict_language(test_text))  # Expected: 'pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVjyhJmTkiSC",
        "outputId": "7ef0679f-e354-461a-c8bc-1c5e9df83615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "X88HQB2RfEoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Normally for text classification problems only [CLS] token is used to rep- resent the whole sentence. Try at least one more possibility on the above dataset: for example, use all the tokens, or use another token, or average the embeddings of all the non-padding tokens. Which performs better?"
      ],
      "metadata": {
        "id": "DhQujZAAfGtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Average the embeddings of all the non-padding tokens："
      ],
      "metadata": {
        "id": "73kgQh_GJTHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers.models.distilbert.modeling_distilbert import DistilBertPreTrainedModel, DistilBertModel\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset and preprocess\n",
        "dataset = load_dataset(\"papluca/language-identification\")"
      ],
      "metadata": {
        "id": "2vXn4-qKGNpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_langs = sorted(list(set(dataset['train']['labels'])))\n",
        "lang2id = {lang: id for id, lang in enumerate(unique_langs)}\n",
        "id2lang = {id: lang for lang, id in lang2id.items()}\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "jjDqPA0qGJwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_batch(batch):\n",
        "    batch['labels'] = [lang2id[label] for label in batch['labels']]\n",
        "    encoding = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
        "    return {**encoding, 'labels': batch['labels']}\n",
        "\n",
        "dataset = dataset.map(encode_batch, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e9e09dbe08a145e3b87dbd2f672d80a2",
            "2900f30843cf43d9b73c643a846d5545",
            "24e85d0314354ac9aeb6452200fc2414",
            "47ffd85be6274d2a83dff1417227bc4e",
            "f9ec3008744d4ee9939dc604620a305f",
            "b64263557b32459b92d7b6271e874f2d",
            "8667ed82a45f488a97c9a6d6e8f2b06e",
            "a10e026db1ce40da81ac4dcae1da5269",
            "94300165b2c646058f420d4aa1caba11",
            "f21392a4c49647819fc199e39c867da0",
            "b32268e9d90a4982b81fff8642f4d7e1"
          ]
        },
        "id": "g8WRdGteGJy1",
        "outputId": "37b26b8c-c5fe-4e9e-c73a-2faa0166ea6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9e09dbe08a145e3b87dbd2f672d80a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom DistilBERT model using average embeddings\n",
        "class DistilBertForAvgSequenceClassification(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "        self.classifier = torch.nn.Linear(config.dim, config.num_labels)\n",
        "        self.dropout = torch.nn.Dropout(config.seq_classif_dropout)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
        "\n",
        "        # Compute average embeddings\n",
        "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
        "        sum_hidden_state = torch.sum(hidden_state * attention_mask_expanded, 1)  # sum across sequence length\n",
        "        mean_hidden_state = sum_hidden_state / attention_mask_expanded.sum(1)  # mean pooling\n",
        "\n",
        "        pooled_output = self.dropout(mean_hidden_state)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n"
      ],
      "metadata": {
        "id": "lTlMHCSUGJ1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = DistilBertForAvgSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(unique_langs))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   output_dir='./results_avg_embedding',\n",
        "   num_train_epochs=3,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   logging_dir='./logs_avg_embedding',\n",
        "   logging_steps=200,\n",
        "   do_train=True,\n",
        "   do_eval=True,\n",
        "   evaluation_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=dataset['train'],\n",
        "   eval_dataset=dataset['validation'],\n",
        "   compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).astype(float).mean().item()}  # Include a metric for evaluation\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kIKkSk5eGJ3n",
        "outputId": "c582b4f0-836a-438d-a6e5-31701936d89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForAvgSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13125' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13125/13125 42:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.397100</td>\n",
              "      <td>0.068299</td>\n",
              "      <td>0.984000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>0.060942</td>\n",
              "      <td>0.987300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.068400</td>\n",
              "      <td>0.061755</td>\n",
              "      <td>0.988100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>0.066838</td>\n",
              "      <td>0.985700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.055200</td>\n",
              "      <td>0.055706</td>\n",
              "      <td>0.988000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.042600</td>\n",
              "      <td>0.064041</td>\n",
              "      <td>0.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.055541</td>\n",
              "      <td>0.989600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.050100</td>\n",
              "      <td>0.060548</td>\n",
              "      <td>0.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.048600</td>\n",
              "      <td>0.084425</td>\n",
              "      <td>0.986800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.036500</td>\n",
              "      <td>0.061293</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.034900</td>\n",
              "      <td>0.038640</td>\n",
              "      <td>0.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.033400</td>\n",
              "      <td>0.068470</td>\n",
              "      <td>0.987900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.032300</td>\n",
              "      <td>0.064287</td>\n",
              "      <td>0.990500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.060174</td>\n",
              "      <td>0.990400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.040600</td>\n",
              "      <td>0.051266</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.070593</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>0.055113</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.027800</td>\n",
              "      <td>0.054878</td>\n",
              "      <td>0.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.048086</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>0.053769</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.027100</td>\n",
              "      <td>0.050416</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>0.053166</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.052127</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.053689</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.087956</td>\n",
              "      <td>0.987900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.009400</td>\n",
              "      <td>0.055899</td>\n",
              "      <td>0.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.054662</td>\n",
              "      <td>0.990900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.025800</td>\n",
              "      <td>0.045470</td>\n",
              "      <td>0.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.047896</td>\n",
              "      <td>0.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.012900</td>\n",
              "      <td>0.065894</td>\n",
              "      <td>0.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.056109</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>0.055530</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.010700</td>\n",
              "      <td>0.057617</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.061635</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>0.061009</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.063944</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.061138</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.016600</td>\n",
              "      <td>0.067119</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.016900</td>\n",
              "      <td>0.066197</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.058105</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.019500</td>\n",
              "      <td>0.045357</td>\n",
              "      <td>0.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.017500</td>\n",
              "      <td>0.052103</td>\n",
              "      <td>0.993100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.059276</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.060485</td>\n",
              "      <td>0.991400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.059435</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.059985</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.057375</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.062389</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.010500</td>\n",
              "      <td>0.066648</td>\n",
              "      <td>0.990600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.059438</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.059180</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.058228</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.055002</td>\n",
              "      <td>0.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.054362</td>\n",
              "      <td>0.993200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>0.051630</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.058463</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.010400</td>\n",
              "      <td>0.058253</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.061314</td>\n",
              "      <td>0.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>0.062549</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.010500</td>\n",
              "      <td>0.064790</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.062552</td>\n",
              "      <td>0.991800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.004600</td>\n",
              "      <td>0.061420</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.062135</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.063889</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.064180</td>\n",
              "      <td>0.991200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13125, training_loss=0.026842183039301918, metrics={'train_runtime': 2558.0797, 'train_samples_per_second': 82.093, 'train_steps_per_second': 5.131, 'total_flos': 1.372304037888e+16, 'train_loss': 0.026842183039301918, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(dataset['test'])\n",
        "print(\"Test Accuracy with Average Embeddings:\", results[\"eval_accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "wiHZbrL9GJ6F",
        "outputId": "4fc319b2-9e0b-4ef5-c8b2-27f920b36dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 00:41]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with Average Embeddings: 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Use another token - Concatenating Tokens\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ISqdnZydJYgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers.models.distilbert.modeling_distilbert import DistilBertPreTrainedModel, DistilBertModel\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"papluca/language-identification\")"
      ],
      "metadata": {
        "id": "MCV3Fw6uGJ8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_langs = sorted(list(set(dataset['train']['labels'])))\n",
        "lang2id = {lang: id for id, lang in enumerate(unique_langs)}\n",
        "id2lang = {id: lang for lang, id in lang2id.items()}\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "s7k773c8GJ-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_batch(batch):\n",
        "    batch['labels'] = [lang2id[label] for label in batch['labels']]\n",
        "    encoding = tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
        "    return {**encoding, 'labels': batch['labels']}\n",
        "\n",
        "dataset = dataset.map(encode_batch, batched=True)"
      ],
      "metadata": {
        "id": "K--WMGWrTe7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBertForConcatSequenceClassification(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "        self.concat_size = 4  # number of tokens to concatenate\n",
        "        self.classifier = torch.nn.Linear(config.dim * self.concat_size, config.num_labels)\n",
        "        self.dropout = torch.nn.Dropout(config.seq_classif_dropout)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        distilbert_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
        "\n",
        "        concat_embedding = hidden_state[:, :self.concat_size].reshape(hidden_state.size(0), -1)  # Taking the first few embeddings and concatenating\n",
        "\n",
        "        pooled_output = self.dropout(concat_embedding)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n"
      ],
      "metadata": {
        "id": "g-lV83lkGKA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = DistilBertForAvgSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(unique_langs))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   output_dir='./results_con_embedding',\n",
        "   num_train_epochs=3,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   logging_dir='./logs_con_embedding',\n",
        "   logging_steps=200,\n",
        "   do_train=True,\n",
        "   do_eval=True,\n",
        "   evaluation_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=dataset['train'],\n",
        "   eval_dataset=dataset['validation'],\n",
        "   compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).astype(float).mean().item()}  # Include a metric for evaluation\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "79o1OqUhThpt",
        "outputId": "064e5c0c-67fb-4a32-d486-168197dd5dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForAvgSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13125' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13125/13125 42:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.350500</td>\n",
              "      <td>0.049768</td>\n",
              "      <td>0.986700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.065100</td>\n",
              "      <td>0.042901</td>\n",
              "      <td>0.988800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.076100</td>\n",
              "      <td>0.110587</td>\n",
              "      <td>0.976400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.051600</td>\n",
              "      <td>0.074622</td>\n",
              "      <td>0.986100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.045400</td>\n",
              "      <td>0.068516</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.042100</td>\n",
              "      <td>0.058273</td>\n",
              "      <td>0.989400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.052043</td>\n",
              "      <td>0.989000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.054500</td>\n",
              "      <td>0.164913</td>\n",
              "      <td>0.964300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.053200</td>\n",
              "      <td>0.129136</td>\n",
              "      <td>0.972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.037900</td>\n",
              "      <td>0.108386</td>\n",
              "      <td>0.978800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>0.078428</td>\n",
              "      <td>0.983200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.031700</td>\n",
              "      <td>0.097226</td>\n",
              "      <td>0.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.083109</td>\n",
              "      <td>0.987800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.046800</td>\n",
              "      <td>0.062816</td>\n",
              "      <td>0.989600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.048828</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.038100</td>\n",
              "      <td>0.061376</td>\n",
              "      <td>0.989500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.027200</td>\n",
              "      <td>0.082715</td>\n",
              "      <td>0.984400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.054122</td>\n",
              "      <td>0.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.036500</td>\n",
              "      <td>0.095835</td>\n",
              "      <td>0.982100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.066736</td>\n",
              "      <td>0.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.051869</td>\n",
              "      <td>0.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.049512</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>0.056245</td>\n",
              "      <td>0.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.009600</td>\n",
              "      <td>0.055546</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.013800</td>\n",
              "      <td>0.054076</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.020800</td>\n",
              "      <td>0.057683</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.051645</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.026500</td>\n",
              "      <td>0.052611</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.051046</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.019400</td>\n",
              "      <td>0.049393</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.015300</td>\n",
              "      <td>0.058144</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>0.140263</td>\n",
              "      <td>0.978100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>0.073315</td>\n",
              "      <td>0.989500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.049431</td>\n",
              "      <td>0.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.046345</td>\n",
              "      <td>0.993100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.010800</td>\n",
              "      <td>0.054567</td>\n",
              "      <td>0.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.063956</td>\n",
              "      <td>0.991200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.055813</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.052451</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.015300</td>\n",
              "      <td>0.051419</td>\n",
              "      <td>0.992900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.048216</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.056003</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.013500</td>\n",
              "      <td>0.065947</td>\n",
              "      <td>0.989500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>0.049374</td>\n",
              "      <td>0.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.046655</td>\n",
              "      <td>0.993500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.046771</td>\n",
              "      <td>0.993600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.054352</td>\n",
              "      <td>0.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>0.049861</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.007100</td>\n",
              "      <td>0.039932</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.045271</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>0.048258</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.050560</td>\n",
              "      <td>0.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.051775</td>\n",
              "      <td>0.992100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.049649</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.051545</td>\n",
              "      <td>0.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.058209</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>0.059428</td>\n",
              "      <td>0.991500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.059910</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.008500</td>\n",
              "      <td>0.062405</td>\n",
              "      <td>0.990900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.059680</td>\n",
              "      <td>0.991300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.004600</td>\n",
              "      <td>0.057537</td>\n",
              "      <td>0.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.057952</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>0.059116</td>\n",
              "      <td>0.991900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.059520</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=13125, training_loss=0.025561480399540492, metrics={'train_runtime': 2563.966, 'train_samples_per_second': 81.904, 'train_steps_per_second': 5.119, 'total_flos': 1.372304037888e+16, 'train_loss': 0.025561480399540492, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "results = trainer.evaluate(dataset['test'])\n",
        "print(\"Test Accuracy with Average Embeddings:\", results[\"eval_accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "wk0kClbqTj2u",
        "outputId": "7d21829d-8a56-4b59-f740-588fe1a00e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with Average Embeddings: 0.991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CLS] Token:\n",
        "- Training Accuracy: 99.4%\n",
        "- Test Accuracy: 99.3%\n",
        "\n",
        "Averaging Tokens:\n",
        "- Training Accuracy: 99.12%\n",
        "- Test Accuracy: 99.04%\n",
        "\n",
        "Concatenating Tokens:\n",
        "- Training Accuracy: 99.2%\n",
        "- Test Accuracy: 99.1%\n",
        "\n",
        "The [CLS] token method shows the best performance with the highest test accuracy. It's closely followed by the Concatenating Tokens method, and then the Averaging All Tokens method.\n",
        "\n",
        "All three methods yield highly impressive results with accuracies above 99% for both training and test datasets. This speaks to the robustness of the training steps employed, as well as the efficacy of the model architectures used.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dhBIXkXSpzTw"
      }
    }
  ]
}